---
title: "HW 6"
author: "Nandini M"
date: "2023-12-02"
output: github_document
  #html_document:
    #toc: true
    #toc_float: true
    #code_folding: hide
---

Load in libraries and set up display settings
```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(mgcv)
library(readxl)
library(knitr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r}
set.seed(123)
```

## Problem 2 

Load in Data:

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

We’ll focus on a simple linear regression with tmax as the response with tmin and prcp as the predictors, and are interested in the distribution of two quantities estimated from these data: r^2, log(β^1 ∗ β^2)
Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. 

```{r}
boot_strap_weather = weather_df |> 
  modelr::bootstrap(n = 5000, id = "strap_number") |> 
  mutate(
    models = map(.x = strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy),
    corr = map(models, broom::glance)) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  filter(term %in% c("tmin","prcp")) |> 
  group_by(strap_number) |> 
  mutate(log_b1x2 = log(sum(estimate))) |> 
  select(log_b1x2, corr) |> 
  unnest(corr) |> 
  janitor::clean_names() |> 
  select(strap_number, log_b1x2, r_squared)

boot_strap_weather
```

Plot the distribution of your estimates, and describe these in words. 

```{r}
corr_dist = boot_strap_weather |> 
  ggplot(aes(x = r_squared)) + geom_density()

print(corr_dist + ggtitle("Density Plot of r^2 Sample Estimates"))

log_dist = boot_strap_weather |> 
  ggplot(aes(x = log_b1x2)) + geom_density()

print(log_dist + ggtitle("Density Plot of log(β^1xβ^2 Sample Estimates"))
```

Across the 5000 bootstrap samples, the value of the sample r-squared estimate approximately ranges between 0.915 to 0.93. There is a high proportion of samples with a correlation coefficient close to 1.

Across the 5000 bootstrap samples, the values of the sample log(β^1 ∗ β^2) estimate approximately ranges between 0.012 to 0.025.

Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r^2 and log(β^1 ∗ β^2).

```{r}
ci_intervals_weather = boot_strap_weather |>
  ungroup() |> 
  summarize(
    corr_ci_lower = quantile(r_squared, 0.025),
    corr_ci_upper = quantile(r_squared, 0.975),
    logb_ci_lower = quantile(log_b1x2, 0.025),
    logb_ci_upper = quantile(log_b1x2, 0.075)
  ) 
```

The 95% Confidence Interval for the r^2 estimates is (`r ci_intervals_weather$corr_ci_lower`, `r ci_intervals_weather$corr_ci_upper`).

The 95% Confidence Interval for the log(β^1 ∗ β^2) estimates is (`r ci_intervals_weather$logb_ci_lower`, `r ci_intervals_weather$logb_ci_upper`).

## Problem 3

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r}
birthweight = 
  read_csv("Data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate_at(c("babysex","frace","malform","mrace"), as.factor) |> 
  drop_na()
```

Propose a regression model for birthweight. 

```{r}
my_model = lm(bwt ~ blength + malform + fincome + smoken + parity + pnumlbw + parity*pnumlbw, data = birthweight)
```

For my model I included blength since the size of the baby may directly impact its birthweight. Additionally, I included factors which are found to be related to low birthweight such as poverty status, cigarette smoking, and malformations. I also believed that number of prior live births alongside previous number of low birth weight babies may act as indicators, with some degree of interaction between these two variables.

```{r}
my_model |> 
  broom::tidy() |> 
  select(term, estimate, p.value) |> 
  knitr::kable(digits = 3)
```

The summary statistics for my proposed model indicate that the the variables all have p-values less than 0.05 except for `malforml` and `parity`.

Show a plot of model residuals against fitted values

```{r}
birthweight |> 
  modelr::add_residuals(my_model) |> 
  modelr::add_predictions(my_model) |> 
  ggplot(aes(x = pred, y = resid)) + geom_point()
```

The residual plot for my model comparing the predicted values with their residuals reveals issues with my models. There appears to be some extreme outliers and a large proportion of the points are clustered between 3000 and 4000 instead of being equally and randomly spread across the plot. There may be variables and interaction terms missing from the model and it is also possible that using linear model is not the best method for this dataset.

Comparing against other models using cross-validated prediction error.

Models 
----------------
*   Model1: length at birth and gestational age as predictors (main effects only)
*   Model2: head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
model1 = lm(bwt ~ blength + gaweeks, data = birthweight)

model2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + 
              bhead*blength*babysex, data = birthweight)
```

```{r}
cv_df = 
  crossv_mc(birthweight, 20) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df |> 
  mutate(
    my_model  = map(train, \(df) lm(bwt ~ blength + malform + fincome + smoken + parity + pnumlbw + parity*pnumlbw, data
                                    = df)),
    model1    = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model2    = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex 
                                    + bhead*blength*babysex, data = df))) |> 
  mutate(
    rmse_my_model = map2_dbl(my_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model1   = map2_dbl(model1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model2   = map2_dbl(model2, test, \(mod, df) rmse(model = mod, data = df)))

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model))|> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Based on the prediction error distribution for each model, it appears that model2, which includes all of the variable interaction terms, has the best predictive accuracy compared to the other two models which mainly focused on main effects and only 1 interaction term. My model had the worst predictive accuracy because it has the highest RSME values compared to the other two models. This analysis shows that incorporating interaction terms and developing more complex models will better model the data rather than simply looking at the main effects of the variables in the dataset.